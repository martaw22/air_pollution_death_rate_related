{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow\n",
    "import time \n",
    "import warnings \n",
    "import numpy as np \n",
    "from numpy import newaxis \n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM \n",
    "from keras.models import Sequential \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_data(filename, seq_len):\n",
    "    f = pd.read_csv(filename)\n",
    "    if f.shape[0] <10:\n",
    "        return [],[],[],[]\n",
    "    \n",
    "    feature_col = [col for col in f.columns if col != \"AQI\"]\n",
    "    label_col = [\"AQI\"]\n",
    "\n",
    "    data = f[feature_col + label_col]\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "\n",
    "    row = round(0.8*data.shape[0])\n",
    "    train = data.iloc[:row, :]\n",
    "    train = scaler.fit_transform(train)\n",
    "    \n",
    "    \n",
    "    np.random.shuffle(train)\n",
    "    train = np.array(train)\n",
    "    x_train = train[:row, :-1]\n",
    "    y_train = train[:row, -1]\n",
    "    \n",
    "    test = data.iloc[row:, :]\n",
    "    test = scaler.transform(test)\n",
    "    test = np.array(test)\n",
    "    x_test = test[:, :-1]\n",
    "    \n",
    "    y_test = test[:, -1]\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "    \n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test], scaler\n",
    "\n",
    "def build_model(layers):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(4, input_shape=(1, 38), return_sequences = True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(4, return_sequences = False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(output_dim = layers[3]))\n",
    "\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "\n",
    "    start  = time.time()\n",
    "    model.compile(loss = \"mse\", optimizer = \"rmsprop\")\n",
    "    print(\"Compilation Time\", time.time() - start)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ =='__main__':\n",
    "\n",
    "    root = \"../data_options/county_features_data/county_features_train/\"\n",
    "    \n",
    "    county_df = pd.read_csv(\"../data_options/data_misc/all_county_names.csv\")\n",
    "    county_list = list(county_df[\"state_county\"].unique())\n",
    "    \n",
    "    epochs = 100\n",
    "    seq_len = 38\n",
    "    \n",
    "    for county in county_list[:5]:\n",
    "    \n",
    "        global_time = time.time()\n",
    "\n",
    "        print('---> Loading data for county {} .... '.format(county))\n",
    "\n",
    "        [X_train, y_train, X_test, y_test], scaler = load_data(root + county + \"_feature.csv\", seq_len)\n",
    "        \n",
    "        pickle.dump(scaler, open(\"../data_options/MinMax_scaler_model/\" + county + \"_scaler.pickle\", \"wb\"))\n",
    "        \n",
    "        \n",
    "        if X_train ==[]:\n",
    "            continue\n",
    "        else:\n",
    "            print('---> Data Loaded. Compiling model ....')\n",
    "\n",
    "\n",
    "        model = build_model([1, 38, 100, 1])\n",
    "\n",
    "        model.fit(\n",
    "            X_train, \n",
    "            y_train,\n",
    "            batch_size = 16, \n",
    "            nb_epoch = epochs,\n",
    "            validation_split = 0.1\n",
    "            )\n",
    "        \n",
    "        model_name = str(county) + \"_model.h5\"\n",
    "        \n",
    "        model.save('../data_options/county_AQI_model/' + model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "        predictions = helpers.predict_point_by_point(model, X_test)\n",
    "        helpers.plot_results(predictions, y_test)\n",
    "        \n",
    "        del model, X_train, y_train, X_test, y_test, model_name, predictions  # deletes the existing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
